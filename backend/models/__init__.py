# æ¨¡å‹æ¨¡å— - åŒ…å«æ‰€æœ‰æ·±åº¦å­¦ä¹ æ¨¡å‹å®šä¹‰ 
import torch
import torch.nn as nn
from .mlp import MLP
from .cnn import CNN
from .rnn import RNN
from .attention_layers import SimpleAttention

def get_model_instance(model_id: str, has_attention: bool = False):
    """
    è·å–æ¨¡å‹å®ä¾‹ã€‚è¿™æ˜¯ä¸€ä¸ªå·¥å‚å‡½æ•°ï¼Œæ ¹æ®æ¨¡å‹IDè¿”å›ç›¸åº”çš„æ¨¡å‹å¯¹è±¡ã€‚
    """
    # å®šä¹‰ä¸éœ€è¦ has_attention å‚æ•°çš„åŸºç¡€æ¨¡å‹
    base_models = {
        'mlp': MLP,
        'cnn': CNN,
        'rnn': RNN
    }
    
    # å®šä¹‰éœ€è¦ has_attention å‚æ•°çš„æ³¨æ„åŠ›æ¨¡å‹
    attention_models = {
        'mlp_attention': MLP,
        'cnn_attention': CNN,
        'rnn_attention': RNN
    }

    if model_id in base_models:
        # å¦‚æœæ˜¯åŸºç¡€æ¨¡å‹ï¼Œç›´æ¥å®ä¾‹åŒ–ï¼Œä¸ä¼ é€’ has_attention
        model_class = base_models[model_id]
        print(f"ğŸ”§ æ­£åœ¨å®ä¾‹åŒ–åŸºç¡€æ¨¡å‹: {model_class.__name__}")
        return model_class()
    elif model_id in attention_models:
        # å¦‚æœæ˜¯æ³¨æ„åŠ›æ¨¡å‹ï¼Œå®ä¾‹åŒ–æ—¶ä¼ é€’ has_attention=True
        model_class = attention_models[model_id]
        print(f"ğŸ”§ æ­£åœ¨å®ä¾‹åŒ–æ³¨æ„åŠ›æ¨¡å‹: {model_class.__name__} with Attention")
        return model_class(has_attention=True)
    else:
        print(f"âŒ æœªçŸ¥çš„æ¨¡å‹ID: {model_id}")
        raise ValueError(f"æœªçŸ¥çš„æ¨¡å‹ID: {model_id}") 