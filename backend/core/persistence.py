import os
import json
import torch
from datetime import datetime

class PersistenceManager:
    """
    å¤„ç†æ‰€æœ‰æ–‡ä»¶ç³»ç»Ÿæ“ä½œï¼ŒåŒ…æ‹¬åŠ è½½/ä¿å­˜æ¨¡å‹ã€æ£€æŸ¥ç‚¹å’Œè®­ç»ƒå†å²ã€‚
    ç¡®ä¿æ‰€æœ‰æ–‡ä»¶æ“ä½œéƒ½æ˜¯çº¿ç¨‹å®‰å…¨çš„ã€‚
    """
    def __init__(self, base_dir, lock):
        self.base_dir = base_dir
        self.history_file = os.path.join(base_dir, 'training_history.json')
        self.checkpoints_dir = os.path.join(base_dir, 'checkpoints')
        self.saved_models_dir = os.path.join(base_dir, 'saved_models')
        self.lock = lock

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.checkpoints_dir, exist_ok=True)
        os.makedirs(self.saved_models_dir, exist_ok=True)

    def save_training_history(self, new_entry):
        """
        ä»¥çº¿ç¨‹å®‰å…¨çš„æ–¹å¼ï¼Œå°†ä¸€æ¡æ–°çš„è®­ç»ƒè®°å½•è¿½åŠ åˆ°å†å²æ–‡ä»¶ä¸­ã€‚
        """
        with self.lock:
            history = self.load_training_history_internal()
            history.append(new_entry)
            try:
                with open(self.history_file, 'w', encoding='utf-8') as f:
                    json.dump(history, f, ensure_ascii=False, indent=4)
            except IOError as e:
                print(f"âŒ æ— æ³•å†™å…¥è®­ç»ƒå†å²æ–‡ä»¶: {e}")

    def load_training_history(self):
        """
        ä»¥çº¿ç¨‹å®‰å…¨çš„æ–¹å¼ï¼ŒåŠ è½½å®Œæ•´çš„è®­ç»ƒå†å²ã€‚
        """
        with self.lock:
            return self.load_training_history_internal()

    def load_training_history_internal(self):
        """
        å†…éƒ¨åŠ è½½æ–¹æ³•ï¼Œä¸åŒ…å«é”ï¼Œä¾›å…¶ä»–å¸¦é”æ–¹æ³•è°ƒç”¨ã€‚
        """
        if not os.path.exists(self.history_file):
            return []
        try:
            with open(self.history_file, 'r', encoding='utf-8') as f:
                # å¤„ç†æ–‡ä»¶ä¸ºç©ºçš„æƒ…å†µ
                content = f.read()
                if not content:
                    return []
                return json.loads(content)
        except (IOError, json.JSONDecodeError) as e:
            print(f"âš ï¸ æ— æ³•åŠ è½½æˆ–è§£æè®­ç»ƒå†å²æ–‡ä»¶ï¼Œå°†è¿”å›ç©ºåˆ—è¡¨: {e}")
            return []

    def clear_training_history(self):
        """
        æ¸…ç©ºè®­ç»ƒå†å²æ–‡ä»¶ã€‚
        """
        with self.lock:
            try:
                with open(self.history_file, 'w', encoding='utf-8') as f:
                    json.dump([], f)
                print("ğŸ§¹ è®­ç»ƒå†å²å·²æ¸…ç©ºã€‚")
            except IOError as e:
                print(f"âŒ æ— æ³•æ¸…ç©ºè®­ç»ƒå†å²æ–‡ä»¶: {e}")


    def save_checkpoint(self, model, model_id, job_id, epoch, accuracy):
        """
        ä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹ã€‚æ–‡ä»¶åç°åœ¨åªä¸ job_id ç›¸å…³ï¼Œä»¥å®ç°è¦†ç›–ä¿å­˜ã€‚
        è¿™ç¡®ä¿äº†æ¯ä¸ªè®­ç»ƒä»»åŠ¡åªåœ¨ç£ç›˜ä¸Šä¿ç•™ä¸€ä¸ªæœ€æ–°çš„"æœ€ä½³"æ£€æŸ¥ç‚¹ã€‚
        """
        filename = f"{job_id}_best.pth"
        filepath = os.path.join(self.checkpoints_dir, filename)
        with self.lock:
            try:
                torch.save(model.state_dict(), filepath)
                print(f"ğŸ’¾ å·²æ›´æ–°æœ€ä½³æ£€æŸ¥ç‚¹: {filepath} (Epoch: {epoch}, Accuracy: {accuracy:.4f})")
            except IOError as e:
                print(f"âŒ ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {e}")

    def save_final_model(self, model, model_id, best_accuracy):
        """
        è®­ç»ƒç»“æŸåï¼Œä¿å­˜æœ€ç»ˆçš„æœ€ä½³æ¨¡å‹ã€‚
        åªæœ‰å½“å½“å‰æ¨¡å‹çš„å‡†ç¡®ç‡é«˜äºå·²ä¿å­˜çš„åŒç±»å‹æœ€ä½³æ¨¡å‹æ—¶ï¼Œæ‰ä¼šä¿å­˜ã€‚
        """
        with self.lock:
            # 1. æ‰«æç°æœ‰åŒç±»å‹æœ€ä½³æ¨¡å‹ï¼Œæ‰¾å‡ºæœ€é«˜å‡†ç¡®ç‡
            highest_existing_acc = 0.0
            existing_best_models = []
            for f in os.listdir(self.saved_models_dir):
                if f.startswith(model_id + '_best_acc_') and f.endswith('.pth'):
                    existing_best_models.append(f)
                    try:
                        # ä»æ–‡ä»¶å 'model-id_best_acc_0.9935.pth' ä¸­æå– '0.9935'
                        acc_str = f.replace(model_id + '_best_acc_', '').replace('.pth', '')
                        acc = float(acc_str)
                        if acc > highest_existing_acc:
                            highest_existing_acc = acc
                    except (ValueError, IndexError):
                        # å¦‚æœæ–‡ä»¶åæ ¼å¼ä¸æ­£ç¡®ï¼Œå°±å¿½ç•¥å®ƒ
                        print(f"âš ï¸ è­¦å‘Šï¼šæ— æ³•ä»æ–‡ä»¶å {f} è§£æå‡†ç¡®ç‡ã€‚")
                        continue

            # 2. æ¯”è¾ƒå‡†ç¡®ç‡
            if best_accuracy > highest_existing_acc:
                print(f"ğŸ† æ–°çºªå½•ï¼å½“å‰æ¨¡å‹å‡†ç¡®ç‡ {best_accuracy:.4f} > å·²æœ‰æœ€é«˜å‡†ç¡®ç‡ {highest_existing_acc:.4f}ã€‚")
                
                # 3. åˆ é™¤æ‰€æœ‰æ—§çš„åŒç±»å‹æœ€ä½³æ¨¡å‹
                for f_to_delete in existing_best_models:
                    try:
                        os.remove(os.path.join(self.saved_models_dir, f_to_delete))
                        print(f"ğŸ—‘ï¸ å·²åˆ é™¤æ—§çš„æœ€ä½³æ¨¡å‹: {f_to_delete}")
                    except OSError as e:
                        print(f"âŒ åˆ é™¤æ—§æ¨¡å‹ {f_to_delete} å¤±è´¥: {e}")

                # 4. ä¿å­˜æ–°çš„æœ€ä½³æ¨¡å‹
                filename = f"{model_id}_best_acc_{best_accuracy:.4f}.pth"
                filepath = os.path.join(self.saved_models_dir, filename)
                try:
                    torch.save(model.state_dict(), filepath)
                    print(f"ğŸ… å·²ä¿å­˜æ–°çš„æœ€ä½³æ¨¡å‹: {filepath}")
                except IOError as e:
                    print(f"âŒ ä¿å­˜æœ€ç»ˆæ¨¡å‹å¤±è´¥: {e}")
            else:
                print(f"ğŸ“‰ æ— éœ€æ›´æ–°ã€‚å½“å‰æ¨¡å‹å‡†ç¡®ç‡ {best_accuracy:.4f} æœªè¶…è¿‡å·²æœ‰çš„æœ€ä½³æ¨¡å‹ (å‡†ç¡®ç‡ {highest_existing_acc:.4f})ã€‚")

    def get_latest_checkpoint(self, model_id):
        """
        æŸ¥æ‰¾å¹¶è¿”å›æŒ‡å®šæ¨¡å‹IDçš„æœ€æ–°æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„ã€‚
        """
        with self.lock:
            checkpoints = [f for f in os.listdir(self.checkpoints_dir) if f.startswith(model_id) and f.endswith('.pth')]
            if not checkpoints:
                return None
            
            # è§£ææ–‡ä»¶åä»¥æŸ¥æ‰¾æœ€æ–°çš„epoch
            latest_checkpoint = max(checkpoints, key=lambda f: int(f.split('_epoch_')[1].split('_acc_')[0]))
            return os.path.join(self.checkpoints_dir, latest_checkpoint) 