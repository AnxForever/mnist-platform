# æŒä¹…åŒ–æ¨¡å— - è¯»å†™ JSON å†å²å’Œæ¨¡å‹æ–‡ä»¶
import json
import os
import threading
import torch
import time
from datetime import datetime

# å…¨å±€é”ï¼Œä¿æŠ¤æ–‡ä»¶å†™æ“ä½œ
FILE_LOCK = threading.Lock()

class PersistenceManager:
    """
    è´Ÿè´£æ‰€æœ‰ä¸æ–‡ä»¶ç³»ç»Ÿç›¸å…³çš„æŒä¹…åŒ–æ“ä½œï¼Œä¾‹å¦‚ä¿å­˜å’ŒåŠ è½½è®­ç»ƒå†å²ã€‚
    è¿™ä¸ªç±»çš„ç›®æ ‡æ˜¯é›†ä¸­ç®¡ç†æ‰€æœ‰I/Oæ“ä½œï¼Œä½¿å…¶æ›´åŠ å¥å£®å’Œæ˜“äºç»´æŠ¤ã€‚
    """
    def __init__(self, base_dir, lock):
        """
        åˆå§‹åŒ–æŒä¹…åŒ–ç®¡ç†å™¨ã€‚
        Args:
            base_dir (str): æ‰€æœ‰æŒä¹…åŒ–æ–‡ä»¶çš„æ ¹ç›®å½•ã€‚
            lock (threading.Lock): ç”¨äºåŒæ­¥æ–‡ä»¶è®¿é—®çš„çº¿ç¨‹é”ã€‚
        """
        self.base_dir = base_dir
        self.models_dir = os.path.join(base_dir, "saved_models")
        self.checkpoints_dir = os.path.join(base_dir, "checkpoints")
        self.history_file = os.path.join(base_dir, "training_history.json")
        self.lock = lock
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.models_dir, exist_ok=True)
        os.makedirs(self.checkpoints_dir, exist_ok=True)
    
    def save_model(self, model, model_id, timestamp=None):
        """ä¿å­˜æœ€ç»ˆè®­ç»ƒå®Œæˆçš„æ¨¡å‹"""
        if timestamp is None:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
        
        model_filename = f"{model_id}_{timestamp}.pth"
        model_path = os.path.join(self.models_dir, model_filename)
        
        torch.save(model.state_dict(), model_path)
        return model_path
    
    def save_checkpoint(self, model, model_id, job_id, epoch, accuracy):
        """ä¿å­˜è®­ç»ƒè¿‡ç¨‹ä¸­çš„æœ€ä½³æ£€æŸ¥ç‚¹"""
        checkpoint_filename = f"{model_id}_{job_id}_best.pth"
        checkpoint_path = os.path.join(self.checkpoints_dir, checkpoint_filename)
        
        checkpoint_data = {
            'model_state_dict': model.state_dict(),
            'epoch': epoch,
            'accuracy': accuracy,
            'model_id': model_id,
            'job_id': job_id,
            'timestamp': time.strftime("%Y-%m-%dT%H:%M:%S")
        }
        
        torch.save(checkpoint_data, checkpoint_path)
        return checkpoint_path
    
    def load_model(self, model_class, model_path):
        """åŠ è½½æ¨¡å‹"""
        model = model_class()
        model.load_state_dict(torch.load(model_path, map_location='cpu'))
        model.eval()
        return model
    
    def save_training_history(self, new_entry):
        """
        ä»¥çº¿ç¨‹å®‰å…¨çš„æ–¹å¼ï¼Œå°†ä¸€æ¡æ–°çš„è®­ç»ƒè®°å½•è¿½åŠ åˆ°å†å²æ–‡ä»¶ä¸­ã€‚
        """
        with self.lock:
            try:
                # 1. è¯»å–ç°æœ‰æ•°æ®
                if os.path.exists(self.history_file) and os.path.getsize(self.history_file) > 0:
                    with open(self.history_file, 'r', encoding='utf-8') as f:
                        history = json.load(f)
                else:
                    history = []
                
                # 2. è¿½åŠ æ–°è®°å½•
                history.append(new_entry)
                
                # 3. å†™å›æ–‡ä»¶
                with open(self.history_file, 'w', encoding='utf-8') as f:
                    json.dump(history, f, ensure_ascii=False, indent=2)
                
                print(f"ğŸ’¾ è®­ç»ƒå†å²å·²ä¿å­˜, Job ID: {new_entry.get('job_id')}")

            except (IOError, json.JSONDecodeError) as e:
                print(f"âŒ ä¿å­˜è®­ç»ƒå†å²å¤±è´¥: {e}")
    
    def load_training_history(self):
        """
        ä»¥çº¿ç¨‹å®‰å…¨çš„æ–¹å¼ï¼Œä»æ–‡ä»¶åŠ è½½å®Œæ•´çš„è®­ç»ƒå†å²ã€‚
        """
        with self.lock:
            try:
                if not os.path.exists(self.history_file):
                    return []
                
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    # æ·»åŠ ä¸€ä¸ªæ£€æŸ¥ï¼Œå¦‚æœæ–‡ä»¶ä¸ºç©ºï¼Œåˆ™è¿”å›ç©ºåˆ—è¡¨ï¼Œé˜²æ­¢json.loadæŠ›å‡ºå¼‚å¸¸
                    content = f.read()
                    if not content:
                        return []
                    return json.loads(content)
            
            except (IOError, json.JSONDecodeError) as e:
                print(f"âŒ åŠ è½½è®­ç»ƒå†å²å¤±è´¥: {e}")
                return []
    
    def get_saved_models(self):
        """è·å–æ‰€æœ‰å·²ä¿å­˜çš„æ¨¡å‹æ–‡ä»¶ä¿¡æ¯"""
        if not os.path.exists(self.models_dir):
            return []
        
        models = []
        for filename in os.listdir(self.models_dir):
            if filename.endswith('.pth'):
                model_info = self._parse_model_filename(filename)
                if model_info:
                    models.append(model_info)
        
        return sorted(models, key=lambda x: x['timestamp'], reverse=True)
    
    def _parse_model_filename(self, filename):
        """è§£ææ¨¡å‹æ–‡ä»¶åï¼Œæå–ä¿¡æ¯"""
        try:
            # æ ¼å¼: {model_id}_{timestamp}.pth
            name_without_ext = filename[:-4]  # ç§»é™¤ .pth
            parts = name_without_ext.split('_')
            
            if len(parts) >= 3:  # model_id, date, time
                model_id = '_'.join(parts[:-2])  # æ”¯æŒå¸¦ä¸‹åˆ’çº¿çš„model_id
                date_time = '_'.join(parts[-2:])
                
                return {
                    "id": filename[:-4],  # å®Œæ•´æ–‡ä»¶åä½œä¸ºID
                    "model_id": model_id,
                    "timestamp": date_time,
                    "filename": filename,
                    "has_attention": "attention" in model_id.lower()
                }
        except Exception:
            pass
        
        return None 